{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erniesg/shareshare/blob/main/dspy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dspy transformers huggingface accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_bQbECOuZmO",
        "outputId": "ea53dade-f8eb-420a-fd8d-5e3af2fd4f18"
      },
      "id": "2_bQbECOuZmO",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dspy\n",
            "  Downloading dspy-0.1.5-py3-none-any.whl (1.3 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.1)\n",
            "Collecting huggingface\n",
            "  Downloading huggingface-0.0.1-py3-none-any.whl (2.5 kB)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.30.0-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.4/302.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dspy-ai==2.4.5 (from dspy)\n",
            "  Downloading dspy_ai-2.4.5-py3-none-any.whl (197 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.5/197.5 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backoff~=2.2.1 (from dspy-ai==2.4.5->dspy)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting joblib~=1.3.2 (from dspy-ai==2.4.5->dspy)\n",
            "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai<2.0.0,>=0.28.1 (from dspy-ai==2.4.5->dspy)\n",
            "  Downloading openai-1.25.1-py3-none-any.whl (312 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.9/312.9 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from dspy-ai==2.4.5->dspy) (2.0.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from dspy-ai==2.4.5->dspy) (2024.4.28)\n",
            "Collecting ujson (from dspy-ai==2.4.5->dspy)\n",
            "  Downloading ujson-5.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.2/53.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dspy-ai==2.4.5->dspy) (4.66.2)\n",
            "Collecting datasets<3.0.0,~=2.14.6 (from dspy-ai==2.4.5->dspy)\n",
            "  Downloading datasets-2.14.7-py3-none-any.whl (520 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m520.4/520.4 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dspy-ai==2.4.5->dspy) (2.31.0)\n",
            "Collecting optuna (from dspy-ai==2.4.5->dspy)\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic==2.5.0 (from dspy-ai==2.4.5->dspy)\n",
            "  Downloading pydantic-2.5.0-py3-none-any.whl (407 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.5/407.5 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==2.5.0->dspy-ai==2.4.5->dspy) (0.6.0)\n",
            "Collecting pydantic-core==2.14.1 (from pydantic==2.5.0->dspy-ai==2.4.5->dspy)\n",
            "  Downloading pydantic_core-2.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic==2.5.0->dspy-ai==2.4.5->dspy) (4.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.0+cpu)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dspy-ai==2.4.5->dspy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dspy-ai==2.4.5->dspy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dspy-ai==2.4.5->dspy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dspy-ai==2.4.5->dspy) (2024.2.2)\n",
            "Collecting pyarrow>=8.0.0 (from datasets<3.0.0,~=2.14.6->dspy-ai==2.4.5->dspy)\n",
            "  Downloading pyarrow-16.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyarrow-hotfix (from datasets<3.0.0,~=2.14.6->dspy-ai==2.4.5->dspy)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets<3.0.0,~=2.14.6->dspy-ai==2.4.5->dspy)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets<3.0.0,~=2.14.6->dspy-ai==2.4.5->dspy)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets<3.0.0,~=2.14.6->dspy-ai==2.4.5->dspy)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec[http]<=2023.10.0,>=2023.1.0 (from datasets<3.0.0,~=2.14.6->dspy-ai==2.4.5->dspy)\n",
            "  Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp (from datasets<3.0.0,~=2.14.6->dspy-ai==2.4.5->dspy)\n",
            "  Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=0.28.1->dspy-ai==2.4.5->dspy) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=0.28.1->dspy-ai==2.4.5->dspy) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=0.28.1->dspy-ai==2.4.5->dspy)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=0.28.1->dspy-ai==2.4.5->dspy) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Collecting alembic>=1.5.0 (from optuna->dspy-ai==2.4.5->dspy)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna->dspy-ai==2.4.5->dspy)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Collecting sqlalchemy>=1.3.0 (from optuna->dspy-ai==2.4.5->dspy)\n",
            "  Downloading SQLAlchemy-2.0.29-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->dspy-ai==2.4.5->dspy) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dspy-ai==2.4.5->dspy) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dspy-ai==2.4.5->dspy) (2024.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna->dspy-ai==2.4.5->dspy)\n",
            "  Downloading Mako-1.3.3-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=0.28.1->dspy-ai==2.4.5->dspy) (1.2.1)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp->datasets<3.0.0,~=2.14.6->dspy-ai==2.4.5->dspy)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,~=2.14.6->dspy-ai==2.4.5->dspy) (23.2.0)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp->datasets<3.0.0,~=2.14.6->dspy-ai==2.4.5->dspy)\n",
            "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5 (from aiohttp->datasets<3.0.0,~=2.14.6->dspy-ai==2.4.5->dspy)\n",
            "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0 (from aiohttp->datasets<3.0.0,~=2.14.6->dspy-ai==2.4.5->dspy)\n",
            "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0 (from aiohttp->datasets<3.0.0,~=2.14.6->dspy-ai==2.4.5->dspy)\n",
            "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=0.28.1->dspy-ai==2.4.5->dspy)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=0.28.1->dspy-ai==2.4.5->dspy)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->dspy-ai==2.4.5->dspy) (1.16.0)\n",
            "Collecting greenlet!=0.4.17 (from sqlalchemy>=1.3.0->optuna->dspy-ai==2.4.5->dspy)\n",
            "  Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.0/616.0 kB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets<3.0.0,~=2.14.6->dspy-ai==2.4.5->dspy)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: huggingface, xxhash, ujson, pydantic-core, pyarrow-hotfix, pyarrow, multidict, Mako, joblib, h11, greenlet, fsspec, frozenlist, dill, colorlog, backoff, async-timeout, yarl, sqlalchemy, pydantic, multiprocess, httpcore, aiosignal, httpx, alembic, aiohttp, accelerate, optuna, openai, datasets, dspy-ai, dspy\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.18.2\n",
            "    Uninstalling pydantic_core-2.18.2:\n",
            "      Successfully uninstalled pydantic_core-2.18.2\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.4.0\n",
            "    Uninstalling joblib-1.4.0:\n",
            "      Successfully uninstalled joblib-1.4.0\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.3.1\n",
            "    Uninstalling fsspec-2024.3.1:\n",
            "      Successfully uninstalled fsspec-2024.3.1\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.7.1\n",
            "    Uninstalling pydantic-2.7.1:\n",
            "      Successfully uninstalled pydantic-2.7.1\n",
            "Successfully installed Mako-1.3.3 accelerate-0.30.0 aiohttp-3.9.5 aiosignal-1.3.1 alembic-1.13.1 async-timeout-4.0.3 backoff-2.2.1 colorlog-6.8.2 datasets-2.14.7 dill-0.3.7 dspy-0.1.5 dspy-ai-2.4.5 frozenlist-1.4.1 fsspec-2023.10.0 greenlet-3.0.3 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 huggingface-0.0.1 joblib-1.3.2 multidict-6.0.5 multiprocess-0.70.15 openai-1.25.1 optuna-3.6.1 pyarrow-16.0.0 pyarrow-hotfix-0.6 pydantic-2.5.0 pydantic-core-2.14.1 sqlalchemy-2.0.29 ujson-5.9.0 xxhash-3.4.1 yarl-1.9.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"HUGGING_FACE_HUB_TOKEN\"] = userdata.get('HUGGING_FACE_HUB_TOKEN')\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "7S-Kp0L2uxKu"
      },
      "id": "7S-Kp0L2uxKu",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "c34a3886",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137,
          "referenced_widgets": [
            "4a645115f5744aeb91ace36f6677c64f",
            "f6a2fb656e6d49e49b87434e6d486107",
            "be58a70f73be4215908aaf703333ae07",
            "857e329d20c04c20a5b5f8a2581db153",
            "67bb2e5ae67f42d0a2bceb1305790093",
            "899f32c2cd414a0f93e9c74a98995e5e",
            "a025bdda90aa48a2abc6006acb2146a5",
            "ec963503a53044869260236dd46bc4fc",
            "5df38417fe704ca2af8b49225e5b5b49",
            "2ed3bb9e09a24d488b2bb79c36c40935",
            "a45f7d894a2c4bce92c9a9a46081663f",
            "b870f0d7509a4eb0a691916e945639bb",
            "0a23e1f2e1c84b0b8c437fd4c0e79e8c",
            "4c7ff33358ff4004a1a18040e2e6ca68",
            "068bc87f4aca4cd9ab9905cd85aa92b0",
            "b739686c9bcf431cbf578f40d96d16fc",
            "9924e472fc4f40e48438af6d67964636",
            "c137cc70d56c47acbbd9dc39c8c8b73d",
            "38cdc887562a4eaba85d6553bcf7f789",
            "0dd224cf62904dffb027690a5fc69063",
            "1725f01247d842f8bfdca14475518ab2",
            "4c22bf4e3a9046a3b1cec9620edc7ee7"
          ]
        },
        "id": "c34a3886",
        "outputId": "b92e0f1f-714b-4370-ee94-1c45d2d621ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a645115f5744aeb91ace36f6677c64f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b870f0d7509a4eb0a691916e945639bb"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import dspy\n",
        "\n",
        "# Set up the LM\n",
        "turbo = dspy.OpenAI(model='gpt-3.5-turbo')\n",
        "qwen = dspy.HFModel(model = 'Qwen/Qwen1.5-7B')\n",
        "llama = dspy.HFModel(model = 'meta-llama/Meta-Llama-3-8B')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3625253",
      "metadata": {
        "id": "b3625253"
      },
      "source": [
        "# Load LogiQA datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "c03ebe95",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c03ebe95",
        "outputId": "925f11d2-29f6-4b77-d57e-d987e505792d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 7376\n",
            "Number of validation examples: 651\n",
            "Number of test examples: 651\n",
            "Number of sampled training examples: 73\n",
            "Number of sampled validation examples: 6\n",
            "Number of sampled test examples: 6\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from dspy import Example\n",
        "import random\n",
        "\n",
        "# Load the dataset with specific splits\n",
        "dataset = load_dataset(\"jiacheng-ye/logiqa-zh\", split={'train': 'train', 'test': 'test', 'validation': 'validation'})\n",
        "\n",
        "def preprocess_function(example):\n",
        "    context = example['context']\n",
        "    query = example['query']\n",
        "    options = example['options']\n",
        "    correct_option = example['correct_option']  # Assuming this field exists and is the index of the correct option\n",
        "\n",
        "    # Format the question\n",
        "    formatted_question = f\"{context}\\n{query}\\n\" + \"\\n\".join([f\"{idx+1}. {option}\" for idx, option in enumerate(options)])\n",
        "\n",
        "    # Add formatted question and correct option to the example\n",
        "    example['formatted_question'] = formatted_question\n",
        "    example['correct_answer'] = options[correct_option]  # Access the correct option using its index\n",
        "    return example\n",
        "\n",
        "# Apply the preprocessing function to each dataset split\n",
        "dataset = {split: ds.map(preprocess_function, batched=False) for split, ds in dataset.items()}\n",
        "\n",
        "# Convert dataset items to DSPy Example objects and set 'formatted_question' as the question and 'correct_answer' as the answer\n",
        "train_dataset = [Example(question=item['formatted_question'], answer=item['correct_answer']).with_inputs('question') for item in dataset[\"train\"]]\n",
        "validation_dataset = [Example(question=item['formatted_question'], answer=item['correct_answer']).with_inputs('question') for item in dataset[\"validation\"]]\n",
        "test_dataset = [Example(question=item['formatted_question'], answer=item['correct_answer']).with_inputs('question') for item in dataset[\"test\"]]\n",
        "\n",
        "# Print the number of examples in each split\n",
        "print(\"Number of training examples:\", len(train_dataset))\n",
        "print(\"Number of validation examples:\", len(validation_dataset))\n",
        "print(\"Number of test examples:\", len(test_dataset))\n",
        "\n",
        "# Sample 10% of the examples from each dataset split\n",
        "sample_size = 0.01\n",
        "train_dataset_sampled = random.sample(train_dataset, int(len(train_dataset) * sample_size))\n",
        "validation_dataset_sampled = random.sample(validation_dataset, int(len(validation_dataset) * sample_size))\n",
        "test_dataset_sampled = random.sample(test_dataset, int(len(test_dataset) * sample_size))\n",
        "\n",
        "# Print the number of examples in each sampled split\n",
        "print(\"Number of sampled training examples:\", len(train_dataset_sampled))\n",
        "print(\"Number of sampled validation examples:\", len(validation_dataset_sampled))\n",
        "print(\"Number of sampled test examples:\", len(test_dataset_sampled))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "9b2c7c71",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b2c7c71",
        "outputId": "d6a12b3c-1673-455b-ca6f-1c5fd13e5810"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: 15. 某城市的房地产开发商只能通过向银行直接贷款或者通过预售商品房来筹集更多的开发资金。政府不允许银行增加对房地产业的直接贷款，结果使得该市的房地产开发商无法筹集到更多的开发资金，因为_______.\n",
            "以下哪个选项能够合逻辑完成上述论证？.\n",
            "1. 的房地产开发商预售商品房后携款潜逃，使得工程竣工遥遥无期。.\n",
            "2. 央银行取消了商品房预售制度。.\n",
            "3. 筑施工企业不愿意垫资施工。.\n",
            "4. 分开发商销售期房后延期交房，使得很多购房者对开发商心存疑惑。.\n",
            "Answer: 央银行取消了商品房预售制度。.\n"
          ]
        }
      ],
      "source": [
        "# Access the formatted question and correct answer in an example from the validation set\n",
        "example = test_dataset_sampled[0]\n",
        "print(\"Question:\", example.question)\n",
        "print(\"Answer:\", example.answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test a baseline prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "6uMO6chKwf3h"
      },
      "id": "6uMO6chKwf3h"
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "3cd9f6d6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cd9f6d6",
        "outputId": "3e26f917-a2ef-44e9-f1ff-4224323dffdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: 15. 某城市的房地产开发商只能通过向银行直接贷款或者通过预售商品房来筹集更多的开发资金。政府不允许银行增加对房地产业的直接贷款，结果使得该市的房地产开发商无法筹集到更多的开发资金，因为_______.\n",
            "以下哪个选项能够合逻辑完成上述论证？.\n",
            "1. 的房地产开发商预售商品房后携款潜逃，使得工程竣工遥遥无期。.\n",
            "2. 央银行取消了商品房预售制度。.\n",
            "3. 筑施工企业不愿意垫资施工。.\n",
            "4. 分开发商销售期房后延期交房，使得很多购房者对开发商心存疑惑。.\n",
            "Prediction:\n",
            "Answer: 2. 央银行取消了商品房预售制度。\n"
          ]
        }
      ],
      "source": [
        "dspy.settings.configure(lm=turbo, max_tokens=4096)\n",
        "predict = dspy.Predict('question -> answer')\n",
        "\n",
        "# Make a prediction\n",
        "prediction = predict(question=test_dataset_sampled[0].question)\n",
        "print(\"Question:\", test_dataset_sampled[0].question)\n",
        "\n",
        "# Print the prediction\n",
        "print(\"Prediction:\")\n",
        "print(prediction.answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "7055fcaf",
      "metadata": {
        "id": "7055fcaf"
      },
      "outputs": [],
      "source": [
        "class BasicQA(dspy.Signature):\n",
        "    \"\"\"Answer the question.\"\"\"\n",
        "\n",
        "    question = dspy.InputField()\n",
        "    answer = dspy.OutputField()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "0e4a547b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e4a547b",
        "outputId": "773eb151-9f7f-4b7d-961b-ee0ae9d7cf91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: 15. 某城市的房地产开发商只能通过向银行直接贷款或者通过预售商品房来筹集更多的开发资金。政府不允许银行增加对房地产业的直接贷款，结果使得该市的房地产开发商无法筹集到更多的开发资金，因为_______.\n",
            "以下哪个选项能够合逻辑完成上述论证？.\n",
            "1. 的房地产开发商预售商品房后携款潜逃，使得工程竣工遥遥无期。.\n",
            "2. 央银行取消了商品房预售制度。.\n",
            "3. 筑施工企业不愿意垫资施工。.\n",
            "4. 分开发商销售期房后延期交房，使得很多购房者对开发商心存疑惑。.\n",
            "Thought: We know that the real estate developers in this city can only raise more development funds by either directly borrowing from banks or through preselling commercial housing. However, the government does not allow banks to increase direct loans to the real estate industry. Therefore, the developers are unable to raise more funds. We need to find an option that logically completes this argument.\n",
            "Predicted Answer: 2. 央银行取消了商品房预售制度。\n"
          ]
        }
      ],
      "source": [
        "# Define the predictor. Notice we're just changing the class. The signature BasicQA is unchanged.\n",
        "generate_answer_with_chain_of_thought = dspy.ChainOfThought(BasicQA)\n",
        "\n",
        "# Call the predictor on the formatted question\n",
        "pred = generate_answer_with_chain_of_thought(question=test_dataset_sampled[0].question)\n",
        "\n",
        "# Print the input, the chain of thought, and the prediction\n",
        "print(f\"Question: {test_dataset_sampled[0].question}\")\n",
        "print(f\"Thought: {pred.rationale.split('.', 1)[1].strip()}\")\n",
        "print(f\"Predicted Answer: {pred.answer}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "b76b9af1",
      "metadata": {
        "id": "b76b9af1"
      },
      "outputs": [],
      "source": [
        "class CoT(dspy.Module):  # let's define a new module\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # here we declare the chain of thought sub-module, so we can later compile it (e.g., teach it a prompt)\n",
        "        self.generate_answer = dspy.ChainOfThought('question -> answer')\n",
        "\n",
        "    def forward(self, question):\n",
        "        return self.generate_answer(question=question)  # here we use the module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "e9216ee5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9216ee5",
        "outputId": "c3b1d8dd-557b-4931-8f19-98b6859fb4b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 3/73 [00:06<02:37,  2.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 2 full traces after 4 examples in round 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from dspy.evaluate import Evaluate\n",
        "from dspy.teleprompt import BootstrapFewShot\n",
        "\n",
        "metric_EM = dspy.evaluate.answer_exact_match\n",
        "\n",
        "teleprompter = BootstrapFewShot(metric=metric_EM, max_bootstrapped_demos=2)\n",
        "cot_compiled = teleprompter.compile(CoT(), trainset=train_dataset_sampled)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qwen.inspect_history(n=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhnG4tvm-Sfe",
        "outputId": "ae467da5-85ce-43d6-e56b-e61743d1a250"
      },
      "id": "NhnG4tvm-Sfe",
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "Answer the question.\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: ${question}\n",
            "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
            "Answer: ${answer}\n",
            "\n",
            "---\n",
            "\n",
            "Question: I have 10 apples. I ate a banana. How many apples do I have left?\n",
            "Reasoning: Let's think step by step in order to\u001b[32mAnswer the question.\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: ${question}\n",
            "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
            "Answer: ${answer}\n",
            "\n",
            "---\n",
            "\n",
            "Question: I have 10 apples. I ate a banana. How many apples do I have left?\n",
            "Reasoning: Let's think step by step in order to answer the question. We start with 10 apples and then eat a banana. We need to subtract the number of apples eaten from the total number of apples to find out how many apples are left.\n",
            "\n",
            "Answer: You have 9 apples left.\n",
            "\n",
            "Question: I have 10 apples. I ate a banana. How many apples do I have left?\n",
            "Reasoning: Let's think step by step in order to answer the question. We start with 10 apples and then eat a banana. We need to subtract the number of apples eaten from the total number of apples to find out how many apples are left.\n",
            "\n",
            "Answer: You have 9 apples left.\n",
            "\n",
            "Question: I have 10 apples. I ate a banana. How many\u001b[0m\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "turbo.inspect_history(n=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAnBVUGnCoYU",
        "outputId": "1f51b742-3e5c-4494-eccf-1d83cc947648"
      },
      "id": "bAnBVUGnCoYU",
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "Given the fields `question`, produce the fields `answer`.\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: ${question}\n",
            "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
            "Answer: ${answer}\n",
            "\n",
            "---\n",
            "\n",
            "Question: ９１为恶意和憎恨所局限的观察者,即使具有敏锐的观察力,也只能见到表面的东西;而只有当敏锐的观察力同善意和热爱相结合,才能探到人和世界的最深处,并且还有希望达到最崇高的目标. 由此可以推出：. 1. Ａ. 世界上没有人能够达到最崇高的目标. 2. Ｂ. 没有敏锐的观察力不可能探到人的最深处. 3. Ｃ. 人性恶是人的表面现象. 4. Ｄ. 有善意的观察者见不到表面的东西.\n",
            "Answer: Ｂ. 没有敏锐的观察力不可能探到人的最深处.\n",
            "\n",
            "---\n",
            "\n",
            "Question: 由于五代时期经常改朝换代,一切因陋就简,顾不上进行新的建设. 所以,后周以前,开封的规模同唐朝差不多. 到郭威建立后周以后,实行政治,经济改革,情况有所好转. 最能准确复述这段话主要意思的是:. 1. 代时期朝代更替频繁. 2. 战乱时期无暇顾及建设发展. 3. 代时期对于都城没有什么建设. 4. 开封的规模在五代同唐朝时差不多.\n",
            "Answer: 代时期对于都城没有什么建设.\n",
            "\n",
            "---\n",
            "\n",
            "Question: 超过半米长的碳纳米管的问世,使其朝应用方向踏出了重要一步. 碳纳米管最重要的应用就是制造“又强又韧又轻又便宜”的材料. 在天然材料中蛛丝最强韧,而碳纳米管纤维的韧性超过了蛛丝,这样的材料在航空航天领域及其重要. 除此之外,碳纳米管还有独特的结构和导电性,可以用来做纳米尺度的电子器件,会比传统的电子器件更小,更灵敏. 但是一般的碳纳米管长度不一,结构类型和导电性不同,很难用来规模化地生产结构和性能一致的器件. 然而现在的超长碳纳米管克服了这一难题,成为一项巨大突破. 这段文字意在说明碳纳米管的? 1. 应用前景. 2. 物理特性. 3. 结构性能. 4. 研究突破.\n",
            "Answer: 应用前景.\n",
            "\n",
            "---\n",
            "\n",
            "Question: 最近举行的一项调查表明,师大附中的学生对滚轴溜冰的着迷程度远远超过其他任何游戏,同时调查发现经常玩滚轴溜冰的学生的平均学习成绩相对其他学生更好一些. 看来,玩滚轴溜冰可以提高学生的学习成绩. 以下哪项如果为真,最能削弱上面的推论? 1. 师大附中与学生家长订了协议,如果孩子的学习成绩的名次没有排在前二十名,双方共同禁止学生玩滚轴溜冰. 2. 玩滚轴溜冰能够锻炼身体,保证学习效率的提高. 3. 玩滚轴溜冰的同学受到了学校有效的指导,其中一部分同学才不至于因此荒废学业. 4. 玩滚轴溜冰有助于智力开发,从而提高学习成绩.\n",
            "Answer: 师大附中与学生家长订了协议,如果孩子的学习成绩的名次没有排在前二十名,双方共同禁止学生玩滚轴溜冰.\n",
            "\n",
            "---\n",
            "\n",
            "Question: 在利益多元,信息网络高度发达的今天,政府的施政离不开公众参与. 闭门造车,我行我素,很容易跟公众产生分歧,并不得不面对来自社会舆论,维稳考量甚至上级机关的压力. 公众还往往因为对决策缺乏预知和了解而对政府产生不信任感,影响政府公信力. 从这个意义上,引入公众参与是政府在施政过程中的必要选择. 这段文字意在说明:. 1. 如何维护公众的知情权. 2. 公众参与政府施政的必要性. 3. 如何保证政府执政的有效性. 4. 政府决策过程透明化的重要性.\n",
            "Answer: 公众参与政府施政的必要性.\n",
            "\n",
            "---\n",
            "\n",
            "Question: 以大投入,大制作,高调造势,高票房回报为标志的“大片”,近几年在中国影坛上出尽风头. 岁末年初开始的《满城尽带黄金甲》全线飘红,以3.5亿元的票房创下了中国电影史上的票房新高. 包括这部片在内的5部影片,占去了2006年中国电影全部26.2亿元票房收入的1/5还多. 但舆论和观众大多给予批评和表示不满. 深究起来,“大片”自身在选材,制作和市场开发方面的诸多误区当是最直接的诱因. 从《英雄》,《无极》,《十面埋伏》,《夜宴》到《满城尽带黄金甲》,国产包括与港台合拍大片几乎是清一色地选择了古装加武打,阴谋加爱情之类型,出现形式奢华和内容空洞的强大反差. 这段文字意在说明? 1. “大片”何时不再自我陶醉. 2. 大投入,大制作影片创下我国电影票房新高. 3. 国产大片形式与内容存在严重脱节. 4. 大片在虚假的市场兴旺的喧嚣中,潜藏着深深的文化危机.\n",
            "Answer: 国产大片形式与内容存在严重脱节.\n",
            "\n",
            "---\n",
            "\n",
            "Question: 去年,某市科研资金总预算中5％是用于社会学科的. 今年,某市经济比去年发展更好,但用于社会学科的科研资金却有所减少. 出现这种情况的原因与其说是经济压力,不如说是社会观念的落后. 以下?项是上述结论所依据的假设. 1. 今年科研资金的总预算比去年略有提高. 2. 社会科学与物理学j生物学具有同等价值. 3. 目前资金的缩减将中断社会学科的研究. 4. 分配给社会学科的研究资金不足以完成必需的工作.\n",
            "Answer: 今年科研资金的总预算比去年略有提高.\n",
            "\n",
            "---\n",
            "\n",
            "Question: 明智的选择胜于盲目的执着. 古人云,塞翁失马,焉知非福. 选择是量力而行的睿智与远见；放弃是顾全大局的果断与胆识. 每个人都市自己生命的唯一导演,只有学会选择与放弃的人才能彻悟人生,笑看人生,拥有海阔天空的人生境界. 根据这段话,以下的理解有误的是? 1. 每个人都应该学会在适当的时候有所选择,有所放弃. 2. 对于一部分人来说,学会选择与放弃并不容易. 3. 学会选择与放弃的人往往比盲目执着的人更易达到一个理想的人生境界. 4. 人生就是一场戏,所以该放弃就放弃,何必太执着.\n",
            "Answer: 人生就是一场戏,所以该放弃就放弃,何必太执着.\n",
            "\n",
            "---\n",
            "\n",
            "Question: 文化焦虑:指在全球化和现代化进程中,基于传统文化受到外来文化的挤压而产生的迷惘,焦躁,失望,不自信等心理状态. 下列不属于文化焦虑的是? 1. 为应对西方文化的入侵,有些家长建议教育部门尽快制定相关政策,让包括四书五经在内的传统经典进入中小学课堂. 2. 全国各地大大小小的城市中,随处可见\"罗马广场\"\"加州小镇\"之类的包含外国地名的广场,小区和公园. 3. 圣诞节,情人节,复活节现在越来越流行,不少传统节日却受到年轻人的冷落,部分学者呼吁尽快采取措施严格限制洋节日. 4. 许多历史文化遗产及人文景观随着如火如荼的旧城改造而不断消失,越来越多的有识之士对此深感忧虑.\n",
            "Answer: 全国各地大大小小的城市中,随处可见\"罗马广场\"\"加州小镇\"之类的包含外国地名的广场,小区和公园.\n",
            "\n",
            "---\n",
            "\n",
            "Question: 过去几十年,中国社会淡化了民族民俗. 随着人们生活富裕,需要用一个个节日掀起娱乐高潮,这时发现我们的传统节日“贫乏”,难以满足人们的精神文化需求,于是,那些富于人情味的洋节便顺理成章地钻入了中国人的生活. 这段话对洋节进入中国人生活的态度是:. 1. 理解. 2. 赞成. 3. 反对. 4. 无所谓.\n",
            "Answer: 理解.\n",
            "\n",
            "---\n",
            "\n",
            "Question: 人类只能知晓\"知\",即\"已知\"和\"未知\",不能知晓\"非知\",更不知道有多少\"非知\"存在.一个造诣高深的科学家,不仅他所知晓的\"已知\"以及他头脑中的\"未知\"要远远多于一般人,而且他对\"非知\"也随时保持高度的警觉,一旦机遇出现,他就能突破头脑中\"已知\"的束缚,竭尽全力地将\"非知\"转化成\"已知\". 据此可以推出（）. 1. \"非知\"转化成已知需要经过\"未知\". 2. 头脑中的\"已知\"有时会成为人类识别\"非知\"的障碍. 3. 普通人是不能识别并捕捉到\"非知\"并将其转化成\"已知\"的. 4. 从哲学的理念上看,应该存在无穷无尽的\"非知\".\n",
            "Answer: 头脑中的\"已知\"有时会成为人类识别\"非知\"的障碍.\n",
            "\n",
            "---\n",
            "\n",
            "Question: 世人皆知,中华民族是一个富有智慧的民族,中国孩子智商高,在各类知识性考试中往往是出类拔萃的,但中国孩子的思考力和创造力较弱. 著名创造教育先驱陶行知先生曾指出:“处处是创造之地,天天是创造之时,人人是创造之人. ”从小培养孩子的创造力,对孩子未来的发展极为重要. 这段话表达的主要意思是:. 1. 中国在孩子的智商方面教育很成功,效果很明显. 2. 创造教育先驱陶行知先生对创造力的解读. 3. 中国应重视孩子在思考力,创造力方面的教育和培养. 4. 中国非常重视孩子智力开发,考试成绩出类拔萃.\n",
            "Answer: 中国应重视孩子在思考力,创造力方面的教育和培养.\n",
            "\n",
            "---\n",
            "\n",
            "Question: 顾客并不像通常所描述的那么容易被操纵. 他们知道自己需要什么. 他们需要的东西,和别人认为他们需要的东西,可能有很大的差别. 据此可知? 1. 广告投资与商品销售不成正比. 2. 大多数人购物认准一种品牌多年不变. 3. 在进入商店前顾客大都知道要买哪种牌子的商品. 4. 顾客在商店购物时一般不喜欢他人的介绍或建议.\n",
            "Answer: 在进入商店前顾客大都知道要买哪种牌子的商品.\n",
            "\n",
            "---\n",
            "\n",
            "Question: 有四个外表看起来没有分别的小球,它们的重量可能有所不同. 取一个天平,将甲,乙归为一组,丙,丁归为另一组,分别放在天平两边,天平是基本平衡的. 将乙,丁对调一下,甲,乙一边明显要比乙,丙一边重得多. 可奇怪的是,我们在天平一边放上甲,丙,而另一边则放上乙,还没有来得及放上丁时,天平就压向了乙一边. 请你判断,甲球与丁球哪个更重? 1. 丁球比甲球重. 2. 丁球比甲球轻. 3. 甲球与丁球同样重. 4. 无法确定甲球与丁球的轻重.\n",
            "Answer: 丁球比甲球重.\n",
            "\n",
            "---\n",
            "\n",
            "Question: 对于雾霾天气,人们深受其害. 殊不知,精神上也存在雾霾现象,如果不及时驱除,就会使心灵压抑灰暗,精神萎靡不振,思想浑浑噩噩,危害一点儿都不比雾霾天气小. 现代社会,节奏快,压力大,矛盾多. 这种精神的雾霾对个人生活和各项事业的害处多多. 如何调适心情,驱散雾霾？一剂良方就是借助文艺的力量,以文“明”志,以文“养”心,以文“怡”情,以文“化”人. 对这段文字理解准确的一项是? 1. 借助文艺有助于驱散精神雾霾. 2. 精神雾霾比雾霾天气更难驱散. 3. 不良生活方式是导致精神雾霾出现的原因. 4. 精神雾霾对人们的危害比雾霾天气更大.\n",
            "Answer: 借助文艺有助于驱散精神雾霾.\n",
            "\n",
            "---\n",
            "\n",
            "Question: 在学术交流会上,一位国外学者以没有遗迹,缺乏相应年代的文字记载而否定夏朝的存在. 以下各项如果为真,最能反驳这位国外学者的是:. 1. 曾经外国考古界以同样的理由否定商朝的存在,但随着对甲骨文研究的加深和殷墟的发现,他们不得不改写对中国历史的记录. 2. 与西方以石头为建筑材料,记录载体不同,我国古代多以木头为建筑材料,记录载体,此外我们还受到地质气候等影响,保存遗迹,文字等难度要更大. 3. 我国有很多关于夏朝的记载和传说,春秋时候杞国人在当时就被认为是夏人后裔,《史记》也有关于夏后氏(夏朝国王)称号等的准确记载. 4. 该学者和团队前不久在爱琴海某小岛发现了尚未明确年代的小型石头建筑,他们结合当地人口头传说故事就认定这是史书记载的某文明.\n",
            "Answer: 与西方以石头为建筑材料,记录载体不同,我国古代多以木头为建筑材料,记录载体,此外我们还受到地质气候等影响,保存遗迹,文字等难度要更大.\n",
            "\n",
            "---\n",
            "\n",
            "Question: 内部言语:一种对自己发出的言语,是自己思考问题时所伴随的一种不出声的言语. 下列属于内部言语的一项是? 1. 培训班学员小声议论这位教师的教学方法. 2. 望着窗外的那一片林子,老张陷入了沉思. 3. 小李站起来,胆怯地望着老师,用很小的声音说:\"我不知道\". 4. 老李与老赵对于是否要打一仗,大声地争执起来.\n",
            "Reasoning: Let's think step by step in order to\u001b[32m produce the answer. We need to identify the scenario where speech is happening internally, within one's own mind. \n",
            "Answer: 望着窗外的那一片林子,老张陷入了沉思.\u001b[0m\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "05cd3a27",
      "metadata": {
        "id": "05cd3a27"
      },
      "outputs": [],
      "source": [
        "NUM_THREADS = 32\n",
        "evaluate_cot = Evaluate(devset=test_dataset_sampled, metric=metric_EM, num_threads=NUM_THREADS, display_progress=True, display_table=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "1153f00c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1153f00c",
        "outputId": "c581616b-e63d-48ac-a0bc-7cb9866d3e80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 2 / 6  (33.3): 100%|██████████| 6/6 [00:01<00:00,  3.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 2 / 6  (33.3%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7e68540af520>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_4f55a th {\n",
              "  text-align: left;\n",
              "}\n",
              "#T_4f55a td {\n",
              "  text-align: left;\n",
              "}\n",
              "#T_4f55a_row0_col0, #T_4f55a_row0_col1, #T_4f55a_row0_col2, #T_4f55a_row0_col3, #T_4f55a_row0_col4, #T_4f55a_row1_col0, #T_4f55a_row1_col1, #T_4f55a_row1_col2, #T_4f55a_row1_col3, #T_4f55a_row1_col4, #T_4f55a_row2_col0, #T_4f55a_row2_col1, #T_4f55a_row2_col2, #T_4f55a_row2_col3, #T_4f55a_row2_col4, #T_4f55a_row3_col0, #T_4f55a_row3_col1, #T_4f55a_row3_col2, #T_4f55a_row3_col3, #T_4f55a_row3_col4, #T_4f55a_row4_col0, #T_4f55a_row4_col1, #T_4f55a_row4_col2, #T_4f55a_row4_col3, #T_4f55a_row4_col4, #T_4f55a_row5_col0, #T_4f55a_row5_col1, #T_4f55a_row5_col2, #T_4f55a_row5_col3, #T_4f55a_row5_col4 {\n",
              "  text-align: left;\n",
              "  white-space: pre-wrap;\n",
              "  word-wrap: break-word;\n",
              "  max-width: 400px;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_4f55a\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_4f55a_level0_col0\" class=\"col_heading level0 col0\" >question</th>\n",
              "      <th id=\"T_4f55a_level0_col1\" class=\"col_heading level0 col1\" >example_answer</th>\n",
              "      <th id=\"T_4f55a_level0_col2\" class=\"col_heading level0 col2\" >rationale</th>\n",
              "      <th id=\"T_4f55a_level0_col3\" class=\"col_heading level0 col3\" >pred_answer</th>\n",
              "      <th id=\"T_4f55a_level0_col4\" class=\"col_heading level0 col4\" >answer_exact_match</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_4f55a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_4f55a_row0_col0\" class=\"data row0 col0\" >15. 某城市的房地产开发商只能通过向银行直接贷款或者通过预售商品房来筹集更多的开发资金。政府不允许银行增加对房地产业的直接贷款，结果使得该市的房地产开发商无法筹集到更多的开发资金，因为_______.\n",
              "以下哪个选项能够合逻辑完成上述论证？.\n",
              "1. 的房地产开发商预售商品房后携款潜逃，使得工程竣工遥遥无期。.\n",
              "2. 央银行取消了商品房预售制度。.\n",
              "3. 筑施工企业不愿意垫资施工。.\n",
              "4. 分开发商销售期房后延期交房，使得很多购房者对开发商心存疑惑。.</td>\n",
              "      <td id=\"T_4f55a_row0_col1\" class=\"data row0 col1\" >央银行取消了商品房预售制度。.</td>\n",
              "      <td id=\"T_4f55a_row0_col2\" class=\"data row0 col2\" >produce the answer. We need to identify the reason why the real estate developers are unable to raise more development funds.</td>\n",
              "      <td id=\"T_4f55a_row0_col3\" class=\"data row0 col3\" >央银行取消了商品房预售制度。</td>\n",
              "      <td id=\"T_4f55a_row0_col4\" class=\"data row0 col4\" >✔️ [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4f55a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_4f55a_row1_col0\" class=\"data row1 col0\" >40. 今年上半年，北京凯华出租汽车公司接到的乘客投诉电话是北京安达出租汽车公司的2倍，这说明安达出租汽车公司比凯华出租汽车公司的管理更规范，服务质量更高。.\n",
              "如果以下陈述为真，哪一项最能支持上述结论?\n",
              "1. 凯华出租汽车公司的投诉电话号码数不如安达出租汽车公司的多。.\n",
              "2. 凯华出租汽车公司的投诉电话数量比安达出租汽车公司的上升得快。.\n",
              "3. 安达出租汽车公司的在运营车辆是凯华出租汽车公司的2倍。.\n",
              "4. 打给凯华出租汽车公司的投诉电话通常比打给安达出租汽车公司的投诉电话时间更长。.</td>\n",
              "      <td id=\"T_4f55a_row1_col1\" class=\"data row1 col1\" >安达出租汽车公司的在运营车辆是凯华出租汽车公司的2倍。.</td>\n",
              "      <td id=\"T_4f55a_row1_col2\" class=\"data row1 col2\" >produce the answer. We need to consider the factors that contribute to the number of complaints received by each company and how it reflects on...</td>\n",
              "      <td id=\"T_4f55a_row1_col3\" class=\"data row1 col3\" >凯华出租汽车公司的投诉电话数量比安达出租汽车公司的上升得快。</td>\n",
              "      <td id=\"T_4f55a_row1_col4\" class=\"data row1 col4\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4f55a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_4f55a_row2_col0\" class=\"data row2 col0\" >40、迄今为止，年代最久远的智人遗骸在非洲出现，距今大约20万年。据此，很多科学家认为，人类起源于非洲，现代人的直系祖先——智人在约20万年前于非洲完成进化后，然后在约15万年到20万年前，慢慢向北迁徙，穿越中东达到欧洲和亚洲，逐步迁徙至世界其他地方。.\n",
              "以下哪项如果为真，最能反驳上述科学家的观点？.\n",
              "1. 现代智人，生活在旧石器时代晚期，大约距今4万年至1万年左右。我国境内，许多地方都有晚期智人化石或者文化遗址发现，地点数以百计.\n",
              "2. 在南美洲的一处考古发掘中，人们发现生活于大约17万年前的智人头骨化石.\n",
              "3. 智人具备了个体之间能够相互沟通，能够制定计划、能够解决种种困难问题的那种非凡的能力.\n",
              "4. 在以色列特拉维夫以东12公里的 Qesem 洞穴中发现了8颗40万年前的智人牙齿，这是科学家迄今为止在全球发现的年代最为久远的智人遗骸.</td>\n",
              "      <td id=\"T_4f55a_row2_col1\" class=\"data row2 col1\" >在以色列特拉维夫以东12公里的 Qesem 洞穴中发现了8颗40万年前的智人牙齿，这是科学家迄今为止在全球发现的年代最为久远的智人遗骸.</td>\n",
              "      <td id=\"T_4f55a_row2_col2\" class=\"data row2 col2\" >produce the answer. We need to identify the evidence that contradicts the theory that modern humans originated in Africa and migrated to other parts of...</td>\n",
              "      <td id=\"T_4f55a_row2_col3\" class=\"data row2 col3\" >在南美洲的一处考古发掘中，人们发现生活于大约17万年前的智人头骨化石.</td>\n",
              "      <td id=\"T_4f55a_row2_col4\" class=\"data row2 col4\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4f55a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_4f55a_row3_col0\" class=\"data row3 col0\" >51、某科研单位2013年新招聘的研究人员，或者具有副高以上职称的“引进人才”，或者是具有北京户籍的应届毕业的博士研究生。应届毕业的博士研究生都居住在博士后公寓中，“引进人才”都居住在“牡丹园”小区。.\n",
              "关于该单位2013年新招聘的研究人员，以下哪项判断是正确的？.\n",
              "1. 居住在博士后公寓的都没有副高以上职称.\n",
              "2. 具有博士学位的都是具有北京户籍的.\n",
              "3. 居住在“牡丹园”小区的都没有博士学位.\n",
              "4. 非应届毕业的博士研究生都居住在“牡丹园”小区.</td>\n",
              "      <td id=\"T_4f55a_row3_col1\" class=\"data row3 col1\" >非应届毕业的博士研究生都居住在“牡丹园”小区.</td>\n",
              "      <td id=\"T_4f55a_row3_col2\" class=\"data row3 col2\" >produce the answer. We need to analyze the given conditions and make logical deductions based on them.</td>\n",
              "      <td id=\"T_4f55a_row3_col3\" class=\"data row3 col3\" >1. 居住在博士后公寓的都没有副高以上职称.</td>\n",
              "      <td id=\"T_4f55a_row3_col4\" class=\"data row3 col4\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4f55a_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_4f55a_row4_col0\" class=\"data row4 col0\" >30．某大学举办围棋比赛。在进行第一轮淘汰赛后，进入第二轮的6位棋手实力相当，不过，还是可以分出高下。在已经进行的两轮比赛中，棋手甲战胜了棋手乙，棋手乙掌声了棋手丙。明天，棋手甲和丙将进行比赛。.\n",
              "请根据题干，从逻辑上预测比赛结果：.\n",
              "1. 手甲肯定会赢.\n",
              "2. 手丙肯定会赢.\n",
              "3. 人将战成平局.\n",
              "4. 手甲很可能赢，但也有可能输.</td>\n",
              "      <td id=\"T_4f55a_row4_col1\" class=\"data row4 col1\" >手甲很可能赢，但也有可能输.</td>\n",
              "      <td id=\"T_4f55a_row4_col2\" class=\"data row4 col2\" >produce the answer. We know that player A defeated player B, and player B defeated player C. Therefore, player A has a higher chance of...</td>\n",
              "      <td id=\"T_4f55a_row4_col3\" class=\"data row4 col3\" >手甲很可能赢，但也有可能输.</td>\n",
              "      <td id=\"T_4f55a_row4_col4\" class=\"data row4 col4\" >✔️ [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4f55a_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_4f55a_row5_col0\" class=\"data row5 col0\" >某一公司有一栋6层的办公楼，公司的财务部、企划部、行政部、销售部、人力资源部、研发部等6个部门在此办公，每个部门占据其中的一层。已知：（1）人力资源部、销售部两个部门所在的楼层不相邻；（2）财务部在企划部下一层；（3）行政部所在的楼层在企划部的上面，但是在人力资源部的下面。.\n",
              "46、以下哪项可能分别是第一层、第二层所在的两个部门？.\n",
              "1. 财务部、销售部.\n",
              "2. 企划部、销售部.\n",
              "3. 研发部、销售部.\n",
              "4. 销售部、企划部.</td>\n",
              "      <td id=\"T_4f55a_row5_col1\" class=\"data row5 col1\" >研发部、销售部.</td>\n",
              "      <td id=\"T_4f55a_row5_col2\" class=\"data row5 col2\" >produce the answer. We need to consider the given conditions and determine the possible arrangement of departments on each floor.</td>\n",
              "      <td id=\"T_4f55a_row5_col3\" class=\"data row5 col3\" >销售部、企划部.</td>\n",
              "      <td id=\"T_4f55a_row5_col4\" class=\"data row5 col4\" >False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33.33"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "evaluate_cot(cot_compiled)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4a645115f5744aeb91ace36f6677c64f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6a2fb656e6d49e49b87434e6d486107",
              "IPY_MODEL_be58a70f73be4215908aaf703333ae07",
              "IPY_MODEL_857e329d20c04c20a5b5f8a2581db153"
            ],
            "layout": "IPY_MODEL_67bb2e5ae67f42d0a2bceb1305790093"
          }
        },
        "f6a2fb656e6d49e49b87434e6d486107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_899f32c2cd414a0f93e9c74a98995e5e",
            "placeholder": "​",
            "style": "IPY_MODEL_a025bdda90aa48a2abc6006acb2146a5",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "be58a70f73be4215908aaf703333ae07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec963503a53044869260236dd46bc4fc",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5df38417fe704ca2af8b49225e5b5b49",
            "value": 4
          }
        },
        "857e329d20c04c20a5b5f8a2581db153": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ed3bb9e09a24d488b2bb79c36c40935",
            "placeholder": "​",
            "style": "IPY_MODEL_a45f7d894a2c4bce92c9a9a46081663f",
            "value": " 4/4 [00:04&lt;00:00,  1.11s/it]"
          }
        },
        "67bb2e5ae67f42d0a2bceb1305790093": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "899f32c2cd414a0f93e9c74a98995e5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a025bdda90aa48a2abc6006acb2146a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec963503a53044869260236dd46bc4fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5df38417fe704ca2af8b49225e5b5b49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ed3bb9e09a24d488b2bb79c36c40935": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a45f7d894a2c4bce92c9a9a46081663f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b870f0d7509a4eb0a691916e945639bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a23e1f2e1c84b0b8c437fd4c0e79e8c",
              "IPY_MODEL_4c7ff33358ff4004a1a18040e2e6ca68",
              "IPY_MODEL_068bc87f4aca4cd9ab9905cd85aa92b0"
            ],
            "layout": "IPY_MODEL_b739686c9bcf431cbf578f40d96d16fc"
          }
        },
        "0a23e1f2e1c84b0b8c437fd4c0e79e8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9924e472fc4f40e48438af6d67964636",
            "placeholder": "​",
            "style": "IPY_MODEL_c137cc70d56c47acbbd9dc39c8c8b73d",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "4c7ff33358ff4004a1a18040e2e6ca68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38cdc887562a4eaba85d6553bcf7f789",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0dd224cf62904dffb027690a5fc69063",
            "value": 4
          }
        },
        "068bc87f4aca4cd9ab9905cd85aa92b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1725f01247d842f8bfdca14475518ab2",
            "placeholder": "​",
            "style": "IPY_MODEL_4c22bf4e3a9046a3b1cec9620edc7ee7",
            "value": " 4/4 [00:04&lt;00:00,  1.03s/it]"
          }
        },
        "b739686c9bcf431cbf578f40d96d16fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9924e472fc4f40e48438af6d67964636": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c137cc70d56c47acbbd9dc39c8c8b73d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38cdc887562a4eaba85d6553bcf7f789": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dd224cf62904dffb027690a5fc69063": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1725f01247d842f8bfdca14475518ab2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c22bf4e3a9046a3b1cec9620edc7ee7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}